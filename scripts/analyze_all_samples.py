#!/usr/bin/env python3
"""
ì™„ì „ë¬´ê²° ë°ì´í„° ë¶„ì„ - 46ê°œ ìƒ˜í”Œ ì „ìˆ˜ ë¶„ì„
GPT-4o mini | temperature: 0.4 ê¸°ì¤€ ìµœì í™”
"""

import csv
import json
from datetime import datetime

# v1.3 ê·œì¹™ì„ Python í•¨ìˆ˜ë¡œ ë³€í™˜
def classify_with_v13_rules(title, content):
    """v1.3 ê·œì¹™ìœ¼ë¡œ ë¶„ë¥˜ (ìˆ˜ë™)"""
    text = (title + " " + content).lower()
    
    # T1ê¸‰-í™•ì‹¤í•œ ìë™ì°¨(â†’1)
    t1_companies = ["í˜„ëŒ€ì°¨", "ê¸°ì•„", "ì‚¼ì„±sdi", "lgì´ë…¸í…", "lgì—ë„ˆì§€ì†”ë£¨ì…˜", "í•œì˜¨ì‹œìŠ¤í…œ", "í¬í‹°íˆ¬ë‹·", "ì±„ë¹„", "ì½”ì˜¤ë¡±ì¸ë”", "í•œêµ­íƒ€ì´ì–´", "ë„¥ì„¼íƒ€ì´ì–´"]
    t1_products = ["ì „ê¸°ì°¨", "ev", "suv", "ì„¸ë‹¨", "í•˜ì´ë¸Œë¦¬ë“œ", "ìŠ¹ìš©ì°¨", "ìƒìš©ì°¨", "íŠ¸ëŸ­", "ë²„ìŠ¤"]
    t1_tech = ["ììœ¨ì£¼í–‰", "adas", "ì™„ì„±ì°¨", "oem", "ì¶©ì „ì¸í”„ë¼", "ê¸‰ì†ì¶©ì „", "ì°¨ëŸ‰ìš©"]
    t1_parts = ["íƒ€ì´ì–´", "ëª¨í„°", "ì—”ì§„", "ë¸Œë ˆì´í¬", "ì—ì–´ë°±"]
    
    # T3ê¸‰-í™•ì‹¤í•œ ë¹„ìë™ì°¨(â†’0)  
    t3_fields = ["ë¶€ë™ì‚°", "ê¸ˆìœµ", "ì •ì¹˜", "êµ°ì‚¬", "ìš°ì£¼", "ì˜ë£Œ", "êµìœ¡", "ê²Œì„", "ìš”ë¦¬", "íŒ¨ì…˜", "ë¬¸í™”", "ìŠ¤í¬ì¸ "]
    t3_industries = ["í†µì‹ ", "í¬í„¸", "ìœ í†µ", "ê±´ì„¤", "ì¡°ì„ ", "í•­ê³µ", "í™”í•™", "ì„ìœ ", "ì² ê°•"]
    
    # T1 í‚¤ì›Œë“œ ì²´í¬
    for keyword in t1_companies + t1_products + t1_tech + t1_parts:
        if keyword in text:
            return 1, f"T1í‚¤ì›Œë“œ: {keyword}"
    
    # ë°°í„°ë¦¬ ë§¥ë½ íŒë‹¨
    if "ë°°í„°ë¦¬" in text:
        if any(x in text for x in ["ì „ê¸°ì°¨", "ì°¨ëŸ‰ìš©", "ev", "ìë™ì°¨"]):
            return 1, "T2-ë°°í„°ë¦¬: ì „ê¸°ì°¨ìš©"
        elif any(x in text for x in ["ê°€ì „", "ess", "íƒœì–‘ê´‘", "ì‚°ì—…ìš©"]):
            return 0, "T2-ë°°í„°ë¦¬: ë¹„ìë™ì°¨ìš©"
    
    # T3 í‚¤ì›Œë“œ ì²´í¬
    for keyword in t3_fields + t3_industries:
        if keyword in text:
            return 0, f"T3í‚¤ì›Œë“œ: {keyword}"
    
    # íŠ¸ë¦­ì¼€ì´ìŠ¤ ì²´í¬
    if "í˜„ëŒ€ì¤‘ê³µì—…" in text:
        return 0, "íŠ¸ë¦­ì¼€ì´ìŠ¤: í˜„ëŒ€ì¤‘ê³µì—…â‰ í˜„ëŒ€ì°¨"
    if "ê¸°ì•„ëŒ€í•™êµ" in text:
        return 0, "íŠ¸ë¦­ì¼€ì´ìŠ¤: ê¸°ì•„ëŒ€í•™êµâ‰ ê¸°ì•„"
    
    # ë¶ˆëª…í™•í•œ ê²½ìš° ë³´ìˆ˜ì  0
    return 0, "ë¶ˆëª…í™•->ë³´ìˆ˜ì 0"

def analyze_all_samples():
    """ì „ì²´ ìƒ˜í”Œ ë¶„ì„"""
    print("ğŸ” ì™„ì „ë¬´ê²° ë°ì´í„° ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    results = []
    correct = 0
    total = 0
    
    with open('data/samples.csv', 'r', encoding='utf-8') as file:
        # BOM ì œê±°
        content = file.read()
        if content.startswith('\ufeff'):
            content = content[1:]
        
        lines = content.strip().split('\n')
        reader = csv.DictReader(lines)
        
        for row in reader:
            sample_id = row['ID']
            title = row['title']
            content_text = row['content']
            actual_label = int(row['label'])
            
            # v1.3 ê·œì¹™ìœ¼ë¡œ ë¶„ë¥˜
            predicted_label, reasoning = classify_with_v13_rules(title, content_text)
            
            is_correct = predicted_label == actual_label
            if is_correct:
                correct += 1
            total += 1
            
            result = {
                'id': sample_id,
                'title': title[:100] + "..." if len(title) > 100 else title,
                'actual': actual_label,
                'predicted': predicted_label,
                'correct': is_correct,
                'reasoning': reasoning,
                'risk_level': 'LOW' if is_correct else 'HIGH'
            }
            results.append(result)
            
            status = 'âœ…' if is_correct else 'âŒ'
            print(f"{sample_id}: {status} ì‹¤ì œ:{actual_label} ì˜ˆì¸¡:{predicted_label} | {reasoning}")
            if not is_correct:
                print(f"   âš ï¸ ì œëª©: {title[:80]}...")
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š ë¶„ì„ ì™„ë£Œ!")
    print(f"ì •í™•ë„: {correct}/{total} = {correct/total*100:.1f}%")
    print(f"ì˜¤ë¶„ë¥˜: {total-correct}ê°œ")
    
    # ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤ ìƒì„¸ ë¶„ì„
    errors = [r for r in results if not r['correct']]
    if errors:
        print(f"\nâŒ ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤ {len(errors)}ê°œ:")
        for i, error in enumerate(errors, 1):
            print(f"{i}. {error['id']}: {error['title']}")
            print(f"   ì‹¤ì œ:{error['actual']} ì˜ˆì¸¡:{error['predicted']} | {error['reasoning']}")
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    with open(f'results/complete_analysis_{timestamp}.json', 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'total_samples': total,
                'correct_predictions': correct,
                'accuracy': correct/total,
                'error_count': len(errors)
            },
            'detailed_results': results,
            'error_analysis': errors
        }, f, ensure_ascii=False, indent=2)
    
    return results, correct/total

def find_improvement_opportunities(results):
    """ê°œì„  ê¸°íšŒ ë¶„ì„"""
    print("\nğŸ” ê°œì„  ê¸°íšŒ ë¶„ì„")
    print("=" * 40)
    
    errors = [r for r in results if not r['correct']]
    
    # íŒ¨í„´ ë¶„ì„
    patterns = {}
    for error in errors:
        key = f"ì‹¤ì œ{error['actual']}â†’ì˜ˆì¸¡{error['predicted']}"
        if key not in patterns:
            patterns[key] = []
        patterns[key].append(error)
    
    for pattern, cases in patterns.items():
        print(f"\nğŸ“ˆ {pattern} íŒ¨í„´: {len(cases)}ê°œ")
        for case in cases:
            print(f"  - {case['id']}: {case['title'][:60]}...")
            print(f"    ì´ìœ : {case['reasoning']}")
    
    return patterns

if __name__ == "__main__":
    results, accuracy = analyze_all_samples()
    patterns = find_improvement_opportunities(results)
    
    print(f"\nğŸ¯ í˜„ì¬ v1.3 ì„±ëŠ¥: {accuracy*100:.1f}%")
    print("ğŸš€ ë‹¤ìŒ: ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤ ê¸°ë°˜ ìŠˆí¼í”„ë¡¬í”„íŠ¸ v2.0 ì„¤ê³„!")
