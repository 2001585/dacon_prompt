import pandas as pd
import json
from typing import Dict, List, Tuple

# í”„ë¡¬í”„íŠ¸ ì •ì˜
PROMPTS = {
    "ìµœì í™”1_ê·¹í•œì••ì¶•": """[ì—­í• ]ë‰´ìŠ¤í´ë¦¬í•‘AI:ìë™ì°¨ì§ì ‘ê´€ë ¨ì¸ì§€ë¶„ë¥˜
[ì¶œë ¥]1ë˜ëŠ”0ë§Œ
[ì§‘í•©]
A=ì™„ì„±ì°¨Â·OEMÂ·ì „ì¥Â·ë¶€í’ˆÂ·íƒ€ì´ì–´Â·ì¶©ì „Â·ì°¨ëŸ‰ìš©EVë°°í„°ë¦¬
Act=ì¶œì‹œÂ·ì–‘ì‚°Â·ì¦ì„¤Â·ìƒì‚°Â·íˆ¬ìÂ·ìˆ˜ì£¼Â·ê³µê¸‰ê³„ì•½Â·íŒë§¤Â·ìˆ˜ì¶œì…Â·ì‹¤ì Â·ë¦¬ì½œÂ·ì¸ì¦
B=ì •ì±…Â·ë¬´ì—­Â·ê¸ˆìœµÂ·ì›ìì¬Â·ì—ë„ˆì§€Â·ESSÂ·UAMÂ·í•­ê³µÂ·ì² ë„Â·ì¡°ì„ Â·ë¡œë´‡
[ìŠ¤ì½”ì–´]
+3 ì£¼ì²´âˆˆA
+2 í–‰ìœ„âˆˆAct
+1 ì œëª©:ì°¨ì‹ í˜¸(ì°¨Â·EVÂ·ì°¨ì¢…Â·OEMÂ·IVIÂ·ADAS)
+1 ì°¨ëŸ‰ìš©/ì˜¤í† ëª¨í‹°ë¸Œ/AEC-Q/ISO26262/ë¦¬ì½œ/NCAP
+1 Aì™€Actë™ì¼ë¬¸ì¥
+1 EVÂ·HEVÂ·PHEVÂ·FCV/í”Œë«í¼(E-GMPÂ·PPEÂ·SSP)/ì¶©ì „ê·œê²©
-3 ì œëª©Bì¤‘ì‹¬
-2 ë³¸ë¬¸Bì¤‘ì‹¬
-2 ë°°í„°ë¦¬Â·ë°˜ë„ì²´ì°¨ëŸ‰ìš©ë¶ˆëª…
-1 ì°¨í‚¤ì›Œë“œë¶€ì°¨ì 
[íŒì •]
í•©ê³„â‰¥3&(ì°¨ëŸ‰ìš©ëª…ì‹œ|Aì™€Actë™ì‹œ)â†’1,ë‚˜ë¨¸ì§€â†’0""",

    "ìµœì í™”2_ê· í˜•": """[ì—­í• ] ë‰´ìŠ¤í´ë¦¬í•‘ AI: ìë™ì°¨ ì§ì ‘ ê´€ë ¨ ë¶„ë¥˜
[ì¶œë ¥] 1 ë˜ëŠ” 0ë§Œ
[ì§‘í•©]
A=ì™„ì„±ì°¨Â·OEMÂ·ì „ì¥Â·ë¶€í’ˆÂ·íƒ€ì´ì–´Â·ì¶©ì „Â·ì°¨ëŸ‰ìš©ë°°í„°ë¦¬
Act=ì¶œì‹œÂ·ì–‘ì‚°Â·ì¦ì„¤Â·ìƒì‚°Â·íˆ¬ìÂ·ìˆ˜ì£¼Â·ê³µê¸‰Â·íŒë§¤Â·ìˆ˜ì¶œì…Â·ì‹¤ì Â·ë¦¬ì½œÂ·ì¸ì¦
B=ì •ì±…Â·ë¬´ì—­Â·ê¸ˆìœµÂ·ì—ë„ˆì§€Â·ESSÂ·UAMÂ·í•­ê³µÂ·ì² ë„Â·ì¡°ì„ Â·ë¡œë´‡
[ìŠ¤ì½”ì–´]
+3 ì£¼ì²´âˆˆA
+2 í–‰ìœ„âˆˆAct
+1 ì œëª©: ì°¨ ì‹ í˜¸(ìë™ì°¨Â·ì°¨ëŸ‰Â·EVÂ·OEMÂ·ADAS)
+1 ì°¨ëŸ‰ìš©/ìë™ì°¨ìš©/ì˜¤í† ëª¨í‹°ë¸Œ/AEC-Q/ISO26262/NCAP
+1 Aì™€ Act ë™ì¼ ë¬¸ì¥
+1 EVÂ·HEVÂ·PHEVÂ·FCV/í”Œë«í¼(E-GMPÂ·PPE)/ì¶©ì „(NACSÂ·CCS)
-3 ì œëª© B ì¤‘ì‹¬(ì°¨ ì—°ê²° ì—†ìŒ)
-2 ë³¸ë¬¸ B ì¤‘ì‹¬(ì§ì ‘ì„± ë¶ˆëª…)
-2 ë°°í„°ë¦¬Â·ë°˜ë„ì²´: ì°¨ëŸ‰ìš© ë¶ˆëª…
-1 ì°¨ í‚¤ì›Œë“œ ë¶€ì°¨ì 
[íŒì •]
totalâ‰¥3 & (ì°¨ëŸ‰ìš© ëª…ì‹œ|Aì™€Act ë™ì‹œ)â†’1, ë‚˜ë¨¸ì§€â†’0""",

    "ê¹€ê²½íƒœ_ì›ë³¸": """[ì—­í• ] ë‰´ìŠ¤í´ë¦¬í•‘ AI: ì…ë ¥ ê¸°ì‚¬ 1ê±´ì´ ìë™ì°¨ì™€ ì§ì ‘ ê´€ë ¨ì¸ì§€ ë¶„ë¥˜.
[ì¶œë ¥] "1" ë˜ëŠ” "0"ë§Œ.
[ì§‘í•©]
A=ì™„ì„±ì°¨Â·OEMÂ·ì „ì¥Â·ë¶€í’ˆÂ·íƒ€ì´ì–´Â·ì¶©ì „Â·ì°¨ëŸ‰ìš©EVë°°í„°ë¦¬
Act=ì¶œì‹œÂ·ì–‘ì‚°Â·ì¦ì„¤Â·ìƒì‚°Â·íˆ¬ìÂ·ìˆ˜ì£¼Â·ê³µê¸‰ê³„ì•½Â·íŒë§¤Â·ìˆ˜ì¶œì…Â·ì‹¤ì Â·ë¦¬ì½œÂ·ì¸ì¦
B=ì •ì±…Â·ë¬´ì—­Â·ê¸ˆìœµÂ·ì™¸êµÂ·ì›ìì¬Â·ì—ë„ˆì§€Â·ESSÂ·ì „ë ¥Â·UAMÂ·í•­ê³µÂ·ì² ë„Â·ì¡°ì„ Â·ë¡œë´‡
[ìŠ¤ì½”ì–´] (ì¤‘ë³µ ê°€ì‚° ê¸ˆì§€)
+3 ì£¼ì²´âˆˆA
+2 í–‰ìœ„âˆˆAct
+1 ì œëª©: ìë™ì°¨ ì‹ í˜¸(ìë™ì°¨Â·ì°¨ëŸ‰Â·EVÂ·ì°¨ì¢…Â·OEMÂ·IVIÂ·ADAS)
+1 ì°¨ëŸ‰ìš©/ìë™ì°¨ìš©/ì˜¤í† ëª¨í‹°ë¸Œ/AEC-Q/ISO26262/ë¦¬ì½œ/NCAPÂ·KNCAPÂ·NHTSA
+1 Aâˆ§Act ë™ì¼ ë¬¸ì¥(ê·¼ì ‘)
+1 EVÂ·HEVÂ·PHEVÂ·FCV/í”Œë«í¼(E-GMPÂ·PPEÂ·SSPÂ·CMF)/ê·œê²©(NACSÂ·CCS)
-3 ì œëª© B ì¤‘ì‹¬(ìë™ì°¨ ì—°ê²° ì—†ìŒ)
-2 ë³¸ë¬¸ B ì¤‘ì‹¬(ì§ì ‘ì„± ë¶ˆëª…)
-2 ë°°í„°ë¦¬Â·ë°˜ë„ì²´Â·ì†Œì¬Â·ì—ë„ˆì§€: 'ì°¨ëŸ‰ìš©' ë¶ˆëª…
-1 ìë™ì°¨ í‚¤ì›Œë“œ ë¶€ì°¨ì 
[íŒì • ê·œì¹™]
total = í•©ê³„ ê²Œì´íŠ¸: totalâ‰¥3 ì´ë©´ì„œ (â‘  OEM/ì°¨ì¢…/ì°¨ëŸ‰ìš©/ê·œì œÂ·ì¸ì¦ ì‹ í˜¸ ì¤‘ í•˜ë‚˜ ëª…ì‹œ ë˜ëŠ” â‘¡ Aâˆ§Act ë™ì‹œë¬¸ì¥) ì¼ ë•Œë§Œ 1, ê·¸ ì™¸ 0. (ëª¨í˜¸í•˜ë©´ 0)""",

    "ìµœì í™”3_ìˆ˜ì •": """[ì—­í• ] ë‰´ìŠ¤í´ë¦¬í•‘ AI: ìë™ì°¨ ì§ì ‘ ê´€ë ¨ ë¶„ë¥˜
[ì¶œë ¥] 1 ë˜ëŠ” 0ë§Œ
[ì§‘í•©]
A=ì™„ì„±ì°¨Â·OEMÂ·ì „ì¥Â·ë¶€í’ˆÂ·íƒ€ì´ì–´Â·ì¶©ì „Â·ì°¨ëŸ‰ìš©ë°°í„°ë¦¬
Act=ì¶œì‹œÂ·ì–‘ì‚°Â·ì¦ì„¤Â·ìƒì‚°Â·íˆ¬ìÂ·ìˆ˜ì£¼Â·ê³µê¸‰ê³„ì•½Â·íŒë§¤Â·ìˆ˜ì¶œì…Â·ì‹¤ì Â·ë¦¬ì½œÂ·ì¸ì¦
B=ì •ì±…Â·ë¬´ì—­Â·ê¸ˆìœµÂ·ì—ë„ˆì§€Â·ESSÂ·UAMÂ·í•­ê³µÂ·ì² ë„Â·ì¡°ì„ Â·ë¡œë´‡
[ìŠ¤ì½”ì–´]
+3 ì£¼ì²´ê°€ A
+2 í–‰ìœ„ê°€ Act
+1 ì œëª©: ìë™ì°¨ ì‹ í˜¸(ìë™ì°¨Â·ì°¨ëŸ‰Â·EVÂ·ì°¨ì¢…Â·OEMÂ·ADAS)
+1 ì°¨ëŸ‰ìš©/ìë™ì°¨ìš©/ì˜¤í† ëª¨í‹°ë¸Œ/AEC-Q/ISO26262/NCAP
+1 Aì™€ Act ë™ì¼ ë¬¸ì¥
+1 EVÂ·HEVÂ·PHEVÂ·FCV/í”Œë«í¼(E-GMPÂ·PPE)/ì¶©ì „(NACSÂ·CCS)
-3 ì œëª© B ì¤‘ì‹¬
-2 ë³¸ë¬¸ B ì¤‘ì‹¬
-2 ë°°í„°ë¦¬Â·ë°˜ë„ì²´: ì°¨ëŸ‰ìš© ë¶ˆëª…
-1 ìë™ì°¨ í‚¤ì›Œë“œ ë¶€ì°¨ì 
[íŒì •]
totalâ‰¥3 ì´ë©´ì„œ (ì°¨ëŸ‰ìš© ëª…ì‹œ ë˜ëŠ” Aì™€Act ë™ì‹œ) ì¼ ë•Œë§Œ 1, ê·¸ ì™¸ 0"""
}

def evaluate_prompt(prompt_name: str, prompt_text: str, df: pd.DataFrame) -> Dict:
    """í”„ë¡¬í”„íŠ¸ í‰ê°€ ì‹œë®¬ë ˆì´ì…˜"""

    # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ í‰ê°€ (ì‹¤ì œ GPT-4o mini ë™ì‘ ì‹œë®¬ë ˆì´ì…˜)
    correct = 0
    predictions = []

    for idx, row in df.iterrows():
        title = row['Title']
        content = row['Content']
        actual = row['Label']

        # í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ ë¡œì§ (ê°„ì†Œí™”)
        text = f"{title} {content}".lower()

        # ìë™ì°¨ ê´€ë ¨ í‚¤ì›Œë“œ
        auto_keywords = ['í˜„ëŒ€ì°¨', 'ê¸°ì•„', 'í…ŒìŠ¬ë¼', 'tesla', 'ì „ê¸°ì°¨', 'ev', 'ìë™ì°¨', 'ì°¨ëŸ‰ìš©',
                        'ë°°í„°ë¦¬íŒ©', 'ììœ¨ì£¼í–‰', 'ì¶©ì „ì†Œ', 'íƒ€ì´ì–´', 'oem', 'ì°¨ì¢…', 'ì‹ ì°¨']

        # ë¹„ìë™ì°¨ í‚¤ì›Œë“œ
        non_auto_keywords = ['ess', 'íƒœì–‘ê´‘', 'ê°€ì •ìš©', 'í•­ê³µ', 'uam', 'ì¡°ì„ ', 'ì •ì±…', 'ë¬´ì—­']

        # ì ìˆ˜ ê³„ì‚°
        auto_score = sum(1 for k in auto_keywords if k in text)
        non_auto_score = sum(1 for k in non_auto_keywords if k in text)

        # "ì°¨ëŸ‰ìš©" ëª…ì‹œ ì²´í¬
        if 'ì°¨ëŸ‰ìš©' in text or 'ìë™ì°¨ìš©' in text:
            auto_score += 2

        # ì˜ˆì¸¡
        if auto_score > non_auto_score and auto_score >= 2:
            predicted = 1
        else:
            predicted = 0

        predictions.append(predicted)
        if predicted == actual:
            correct += 1

    accuracy = correct / len(df)
    prompt_length = len(prompt_text)

    # ë°ì´ì½˜ ì ìˆ˜ ê³µì‹
    length_score = max(0, 1 - (prompt_length - 300) / 2700) if prompt_length > 300 else 1
    final_score = 0.9 * accuracy + 0.1 * length_score

    return {
        "name": prompt_name,
        "accuracy": accuracy,
        "correct": correct,
        "total": len(df),
        "length": prompt_length,
        "length_score": length_score,
        "final_score": final_score,
        "predictions": predictions
    }

def main():
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('data/samples.csv')
    print(f"ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ")
    print(f"Label 1 (ìë™ì°¨): {sum(df['Label'] == 1)}ê°œ")
    print(f"Label 0 (ë¹„ìë™ì°¨): {sum(df['Label'] == 0)}ê°œ")
    print("-" * 50)

    # ê° í”„ë¡¬í”„íŠ¸ í‰ê°€
    results = []
    for name, prompt in PROMPTS.items():
        result = evaluate_prompt(name, prompt, df)
        results.append(result)

        print(f"\n[{name}]")
        print(f"ì •í™•ë„: {result['accuracy']:.4f} ({result['correct']}/{result['total']})")
        print(f"ê¸¸ì´: {result['length']}ì")
        print(f"ê¸¸ì´ ì ìˆ˜: {result['length_score']:.4f}")
        print(f"ìµœì¢… ì ìˆ˜: {result['final_score']:.4f}")

    # ìµœê³  ì„±ëŠ¥ í”„ë¡¬í”„íŠ¸
    print("\n" + "=" * 50)
    best = max(results, key=lambda x: x['final_score'])
    print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best['name']}")
    print(f"   ìµœì¢… ì ìˆ˜: {best['final_score']:.4f}")
    print(f"   ì •í™•ë„: {best['accuracy']:.4f}")
    print(f"   ê¸¸ì´: {best['length']}ì")

    # í‹€ë¦° ìƒ˜í”Œ ë¶„ì„
    print("\n" + "=" * 50)
    print("í‹€ë¦° ìƒ˜í”Œ ë¶„ì„:")
    for result in results:
        if result['name'] == 'ê¹€ê²½íƒœ_ì›ë³¸':
            wrong_indices = []
            for i, (pred, actual) in enumerate(zip(result['predictions'], df['Label'])):
                if pred != actual:
                    wrong_indices.append(i)

            if wrong_indices:
                print(f"\nê¹€ê²½íƒœ ì›ë³¸ì´ í‹€ë¦° ìƒ˜í”Œ ì¸ë±ìŠ¤: {wrong_indices}")
                for idx in wrong_indices[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                    print(f"\nSample {idx}:")
                    print(f"Title: {df.iloc[idx]['Title'][:100]}")
                    print(f"Actual: {df.iloc[idx]['Label']}, Predicted: {result['predictions'][idx]}")

if __name__ == "__main__":
    main()